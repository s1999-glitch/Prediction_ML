{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02967bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Medicine Name  Dosage     Form        Frequency      Duration  \\\n",
      "0       Aspirin   500mg   Tablet       Once daily        7 days   \n",
      "1     Metformin  1000mg   Tablet      Twice daily       30 days   \n",
      "2     Ibuprofen   200mg   Tablet  Every 4-6 hours     As needed   \n",
      "3   Amoxicillin   500mg  Capsule      Twice daily       10 days   \n",
      "4    Lisinopril    10mg   Tablet       Once daily  Indefinitely   \n",
      "\n",
      "            High Risk            Low Risk  \n",
      "0         Memory loss  Exercise regularly  \n",
      "1  Frequent confusion  Exercise regularly  \n",
      "2  Frequent confusion  Exercise regularly  \n",
      "3   Cognitive decline  Exercise regularly  \n",
      "4  Frequent confusion  Exercise regularly  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "file_path = 'expanded_risk_medicine_data (1).csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to understand the data structure\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cdaf3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define evaluation functions\n",
    "def calculate_precision(actual, recommended):\n",
    "    true_positives = len(actual & recommended)\n",
    "    total_predicted_positives = len(recommended)\n",
    "    return true_positives / total_predicted_positives if total_predicted_positives > 0 else 0\n",
    "\n",
    "def calculate_recall(actual, recommended):\n",
    "    true_positives = len(actual & recommended)\n",
    "    total_actual_positives = len(actual)\n",
    "    return true_positives / total_actual_positives if total_actual_positives > 0 else 0\n",
    "\n",
    "def calculate_f1_score(precision, recall):\n",
    "    return 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "def calculate_accuracy(actual, recommended):\n",
    "    correct_recommendations = len(actual & recommended)\n",
    "    total_recommendations = len(actual | recommended)\n",
    "    return correct_recommendations / total_recommendations if total_recommendations > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f34dc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.50\n",
      "Recall: 0.50\n",
      "F1-Score: 0.50\n",
      "Accuracy: 0.33\n"
     ]
    }
   ],
   "source": [
    "# Placeholder for actual and recommended medication sets\n",
    "# These should be derived from your system's outputs and actual needs\n",
    "actual_medications = {'Aspirin', 'Metformin'}  # Example set of actual medications needed\n",
    "recommended_medications = {'Aspirin', 'Ibuprofen'}  # Example set of medications recommended by the system\n",
    "\n",
    "# Calculate metrics\n",
    "precision = calculate_precision(actual_medications, recommended_medications)\n",
    "recall = calculate_recall(actual_medications, recommended_medications)\n",
    "f1_score = calculate_f1_score(precision, recall)\n",
    "accuracy = calculate_accuracy(actual_medications, recommended_medications)\n",
    "\n",
    "# Print results\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1_score:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f8dd706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd2decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'Updated_Alzheimers_Data_Numeric.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26aeda87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the confidence threshold\n",
    "confidence_threshold = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bc83c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target variable (binary classification)\n",
    "data['Target'] = (data['High_Confidence_Limit'] > confidence_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61035ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target, including additional features for better model performance\n",
    "features = data[['Topic_Numeric', 'Question_Numeric', 'Data_Value', 'Low_Confidence_Limit', 'High_Confidence_Limit']]\n",
    "target = data['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42138f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunam\\AppData\\Local\\Temp\\ipykernel_19580\\3016675717.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['Confidence_Width'] = data['High_Confidence_Limit'] - data['Low_Confidence_Limit']\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering: Creating new feature as the difference in confidence limits\n",
    "features['Confidence_Width'] = data['High_Confidence_Limit'] - data['Low_Confidence_Limit']\n",
    "# Preprocessing for numeric columns (Standard Scaling)\n",
    "numeric_features = ['Topic_Numeric', 'Question_Numeric', 'Data_Value', 'Low_Confidence_Limit', 'High_Confidence_Limit', 'Confidence_Width']\n",
    "numeric_preprocessor = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8234d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', numeric_preprocessor, numeric_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a neural network classifier with hyperparameter tuning using GridSearchCV\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'classifier__hidden_layer_sizes': [(50, 30), (100, 50), (100,)],\n",
    "    'classifier__activation': ['tanh', 'relu'],\n",
    "    'classifier__solver': ['adam', 'sgd'],\n",
    "    'classifier__alpha': [0.0001, 0.001],\n",
    "    'classifier__learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "# Create a pipeline with preprocessing and neural network classifier\n",
    "neural_network_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', mlp)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81479391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=constant, classifier__solver=adam; total time=  19.0s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=constant, classifier__solver=adam; total time=  27.2s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=constant, classifier__solver=adam; total time=  29.0s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=constant, classifier__solver=adam; total time=  25.1s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=constant, classifier__solver=adam; total time=  15.0s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=constant, classifier__solver=sgd; total time=  32.1s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=constant, classifier__solver=sgd; total time=  31.8s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=constant, classifier__solver=sgd; total time=  28.0s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=constant, classifier__solver=sgd; total time=  29.8s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=constant, classifier__solver=sgd; total time=  32.0s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=adaptive, classifier__solver=adam; total time=  16.1s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=adaptive, classifier__solver=adam; total time=  25.9s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=adaptive, classifier__solver=adam; total time=  32.2s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=adaptive, classifier__solver=adam; total time=  24.4s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=adaptive, classifier__solver=adam; total time=  14.8s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=adaptive, classifier__solver=sgd; total time= 1.4min\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=adaptive, classifier__solver=sgd; total time= 1.4min\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=adaptive, classifier__solver=sgd; total time= 1.2min\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=adaptive, classifier__solver=sgd; total time= 1.1min\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(50, 30), classifier__learning_rate=adaptive, classifier__solver=sgd; total time= 1.4min\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(100, 50), classifier__learning_rate=constant, classifier__solver=adam; total time=  34.1s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(100, 50), classifier__learning_rate=constant, classifier__solver=adam; total time=  30.5s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(100, 50), classifier__learning_rate=constant, classifier__solver=adam; total time=  32.3s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(100, 50), classifier__learning_rate=constant, classifier__solver=adam; total time=  55.5s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(100, 50), classifier__learning_rate=constant, classifier__solver=adam; total time=  27.1s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(100, 50), classifier__learning_rate=constant, classifier__solver=sgd; total time=  52.2s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(100, 50), classifier__learning_rate=constant, classifier__solver=sgd; total time=  49.1s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(100, 50), classifier__learning_rate=constant, classifier__solver=sgd; total time=  50.1s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(100, 50), classifier__learning_rate=constant, classifier__solver=sgd; total time=  48.4s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(100, 50), classifier__learning_rate=constant, classifier__solver=sgd; total time=  56.0s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(100, 50), classifier__learning_rate=adaptive, classifier__solver=adam; total time=  36.4s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(100, 50), classifier__learning_rate=adaptive, classifier__solver=adam; total time=  33.6s\n",
      "[CV] END classifier__activation=tanh, classifier__alpha=0.0001, classifier__hidden_layer_sizes=(100, 50), classifier__learning_rate=adaptive, classifier__solver=adam; total time=  31.4s\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(neural_network_pipeline, param_grid, cv=5, scoring='roc_auc', verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "# Evaluate the model using the best estimator\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_nn = best_model.predict(X_test)\n",
    "y_pred_proba_nn = best_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233fef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Simulate some results\n",
    "actual = ['High Risk', 'High Risk', 'High Risk', 'High Risk', 'Low Risk']\n",
    "predicted = ['High Risk', 'High Risk', 'High Risk', 'High Risk', 'High Risk']\n",
    "\n",
    "# Generate and display confusion matrix\n",
    "cm = confusion_matrix(actual, predicted, labels=['High Risk', 'Low Risk'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['High Risk', 'Low Risk'])\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix for Medication Recommendation System')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441beddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e77f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e4f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7582f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb058e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0c298f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7de861a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cf46ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
